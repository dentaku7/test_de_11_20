{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/code')\n",
    "\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client\n",
    "from os import environ\n",
    "from task_2_generate_data import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HOST = environ[\"DB_HOST\" ]\n",
    "DASK_SCHEDULER_ADDRESS = environ[\"DASK_SCHEDULER_ADDRESS\"]\n",
    "DATA_DIR = environ[\"TASK_2_DATA_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_uri = f\"postgresql://postgres:postgres@{DB_HOST}:5432/task_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = Client(\"tcp://scheduler:8786\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask дашборд: (http://127.0.0.1:8787)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор dask продиктован необходимостью уметь масштабироваться и работать с big-data.\n",
    "Я не очень хорошо знаком с pandas и dask но кажется что эти инструменты хорошо подходят для демо чтобы не пилить эту задачу вечно.\n",
    "\n",
    "Также я не знаком с термином \"реконсиляция\", пришлось гуглить. Надеюсь что основную идею задачи уловил верно.\n",
    "\n",
    "Для строк и дат реконсиляцию делать не стал, так как работа с датами это то же самое - перевести даты в unix timestamp и работать с числами (секундами, миллисекундами), а сравнение строк это случай когда толеранс - 0. Для pandas код будет выглядеть одинаково."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта команда:\n",
    "#   Создаст базу данных вместе с таблицами\n",
    "#   Сгенерирует фейковые данные в CSV и загрузит их в базу\n",
    "#   Изменит некоторые строки в CSV\n",
    "\n",
    "generate_data(total_files=10,\n",
    "              lines_per_file=100000,\n",
    "              changed_lines_per_files=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запрос для чтения данных из БД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подразумевается, что данные в таблице не изменяются за период чтения. Если это не так, то необходимо предусмотреть дополнительную логику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "select t.*\n",
    "from tb_transactions as t\n",
    "         left join (\n",
    "    select transaction_id, ntile({pages_total}) over (order by transaction_id) as page\n",
    "    from tb_transactions\n",
    ") as p on p.transaction_id = t.transaction_id\n",
    "where p.page = {page};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источник 1 - БД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "генерируем lazy-load computations для dask.\n",
    "Команда .set_index() вызывает полное чтение данных из бд (неоптимально, но для демо сойдёт).\n",
    "(можно использовать .persist() для избежания повторных чтений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pages = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_1 = dd.from_delayed([\n",
    "    delayed(pd.read_sql_query)(QUERY.format(pages_total=total_pages, page=page+1), sql_uri)\n",
    "    for page in range(total_pages)\n",
    "]).persist().set_index('transaction_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источник 2 - CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_2 = dd.read_csv(f'{DATA_DIR}/transactions_*.csv', \n",
    "                  header=None, parse_dates=['transaction_date'],\n",
    "                  names=['user_uid', 'transaction_id', 'transaction_date', 'transaction_type', 'amount']\n",
    "                         ).set_index('transaction_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реконсиляция с заданным толеранс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 0.1 # set tolerance in %percents%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_source_1\n",
    "    .merge(df_source_2, how='outer', on='transaction_id')\n",
    ")\n",
    "\n",
    "df_difference_idx = df[\n",
    "    (abs((df['amount_y'] - df['amount_x'])/df['amount_x']) > (tolerance / 100)) \n",
    "    | (df['amount_x'].isnull())\n",
    "    | (df['amount_y'].isnull())\n",
    "].compute().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Найдено {len(df_difference_idx)} отличающихся записей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difference_idx[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собираем реконсилированые данные по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reconciliated = df_source_1.loc[~df_source_1.index.isin(df_difference_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Очищенные данные содержат {len(df_reconciliated)} записей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reconciliated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reconciliated['month'] = df_reconciliated['transaction_date'].dt.to_period('M').dt.to_timestamp()\n",
    "df_reconciliated['day'] = df_reconciliated['transaction_date'].dt.round('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_user = (\n",
    "    df_reconciliated\n",
    "    .groupby('user_uid').sum()\n",
    ")\n",
    "total_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_user_per_month = (\n",
    "    df_reconciliated\n",
    "    .groupby(['user_uid', 'month']).sum()\n",
    ")\n",
    "total_per_user_per_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_user_per_day = (\n",
    "    df_reconciliated\n",
    "    .groupby(['user_uid', 'day']).sum()\n",
    ")\n",
    "total_per_user_per_day.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
